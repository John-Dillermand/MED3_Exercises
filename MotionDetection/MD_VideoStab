# import libraries
#from vidgear.gears import VideoGear
#from vidgear.gears import WriteGear
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt
  

## infinite loop
#while True:
#
#    frame = stream.read()
#    # read stabilized frames
#
#    # check if frame is None
#    if frame is None:
#        #if True break the infinite loop
#        break
#
#    # do something with stabilized frame here
#
#    cv.imshow("Stabilized Frame", frame)
#    # Show output window
#
#    key = cv.waitKey(1) & 0xFF
#    # check for 'q' key-press
#    if key == ord("q"):
#        #if 'q' key-pressed break out
#        break



#Uncomment this to enable video stabilization
#stream = VideoGear(source=1, stabilize = True).start()

def motionDetection(camera):
	# define a video capture object
	vid = cv.VideoCapture(camera)
	#vid = stream

	frameCount = 0
	previousFrame = None


	# Malisiewicz et al.
	def non_max_suppression_fast(boxes, overlapThresh):
		# if there are no boxes, return an empty list
		if len(boxes) == 0:
			return []
		# if the bounding boxes integers, convert them to floats --
		# this is important since we'll be doing a bunch of divisions
		if boxes.dtype.kind == "i":
			boxes = boxes.astype("float")
		# initialize the list of picked indexes	
		pick = []
		# grab the coordinates of the bounding boxes
		x1 = boxes[:,0]
		y1 = boxes[:,1]
		x2 = boxes[:,2]
		y2 = boxes[:,3]
		# compute the area of the bounding boxes and sort the bounding
		# boxes by the bottom-right y-coordinate of the bounding box
		area = (x2 - x1 + 1) * (y2 - y1 + 1)
		idxs = np.argsort(y2)
		# keep looping while some indexes still remain in the indexes
		# list
		while len(idxs) > 0:
			# grab the last index in the indexes list and add the
			# index value to the list of picked indexes
			last = len(idxs) - 1
			i = idxs[last]
			pick.append(i)
			# find the largest (x, y) coordinates for the start of
			# the bounding box and the smallest (x, y) coordinates
			# for the end of the bounding box
			xx1 = np.maximum(x1[i], x1[idxs[:last]])
			yy1 = np.maximum(y1[i], y1[idxs[:last]])
			xx2 = np.minimum(x2[i], x2[idxs[:last]])
			yy2 = np.minimum(y2[i], y2[idxs[:last]])
			# compute the width and height of the bounding box
			w = np.maximum(0, xx2 - xx1 + 1)
			h = np.maximum(0, yy2 - yy1 + 1)
			# compute the ratio of overlap
			overlap = (w * h) / area[idxs[:last]]
			# delete all indexes from the index list that have
			idxs = np.delete(idxs, np.concatenate(([last],
				np.where(overlap > overlapThresh)[0])))
		# return only the bounding boxes that were picked using the
		# integer data type
		return boxes[pick].astype("int")

	while(True):
		
		# Capture the video frame
		# by frame
		ref, frame = vid.read()


		grayFrame = cv.cvtColor (frame,cv.COLOR_BGR2GRAY)
		blurredFrame= cv.GaussianBlur(grayFrame,(5,5),0)
		preparedFrame = blurredFrame
		if (previousFrame is None):
			previousFrame = preparedFrame

		diffFrame = cv.absdiff(src1=previousFrame,src2=preparedFrame)
		previousFrame = preparedFrame

		#Dilute the image to make differences more seeable
		kernel = np.ones((7,7))
		diffFrame = cv.dilate(diffFrame,kernel,1)
		threshFrame= cv.threshold(src=diffFrame, thresh=20, maxval=255,type=cv.THRESH_BINARY)[1]
		#erodedFrame = cv.erode(threshFrame,kernel,None,(-1,-1),2)
		contours, _ = cv.findContours(image=threshFrame, mode=cv.RETR_EXTERNAL, method=cv.CHAIN_APPROX_SIMPLE)
		for contour in contours:
			if cv.contourArea(contour) < 50:
				# too small: skip!
				continue
			
			(x, y, w, h) = cv.boundingRect(contour)
			cv.rectangle(img=frame, pt1=(x, y), pt2=(x + w, y + h), color=(0, 255, 0), thickness=2)

		# Display the resulting frame
		cv.imshow('ThreshedFrame', threshFrame)
		cv.imshow('Img', frame)
		
		if cv.waitKey(1) & 0xFF == ord('0'):
			
			break
	

	# Destroy all the windows
	cv.destroyAllWindows()




motionDetection(0)